 Everyone, welcome to the podcast. We're going to talk about OpenAI's response to New York Times' recent lawsuit. I am joined by Crystal Laser. She is a lawyer and professor from Cleveland State. So, Crystal, thanks for joining us. What we're going to do is just quickly go through the comments that OpenAI made on New York Times lawsuit. So, I'm going to start reading. OpenAI mentioned our goals develop AI tools and empower people to solve problems. Otherwise, out of reach, while we disagree with the claims in New York Times lawsuit, we view it as an opportunity to clarify our business, our intent, and how we build our technology. Our position can be summed up in these four points, which we flesh out below. One, we collaborate with news organizations in our creating new opportunities. Two, training is fair use, but we provide an opt-out because it's the right thing to do. Three, regurgitation is a rare bug that we're working to drive zero. And four, the New York Times is not telling us the full story. So, let me dive in number one, and then we'd love to hear what your comments are, and then we can go to two, three, and four. So, one, we collaborate with news organizations in our creating new opportunities. We work hard in our technology design process to support news organizations. We've met with dozens as well as leading industry organizations like News Media Alliance to explore opportunities, discuss their concerns, and provide solutions. We aim to learn, educate, listen, and listen to feedback and adapt. Our goals are to support a healthy news ecosystem, be a good partner, and create mutually beneficial opportunities. With this in mind, we have pursued partnership with news organizations to achieve these objectives. One, deploy our products to benefit and support reporters and editors by assisting with time-consuming, task-like analyzing, volumous, volumous, public records, and transling stories, I can't speak English, it's terrible. Teach our AI models about the world by training on additional historical and non-publicly available content, display real time content with attribution and chat to you, providing new ways for news publishers to connect with readers. So that was point one. Any thoughts on that? Yeah, so I think what they're trying to show here is more for publicity than on the legal side. I think trying to say, look, we are trying to find non-legal solutions to many of the problems that are raised by creators, especially news organizations, and that they're trying to find ways to create partnerships with those organizations that would be mutually beneficial by, for example, highlighting and linking to the content of those news organizations, it sounds like that's what they were proposing in some of the initial negotiations with the New York Times, and that that's something that they're trying to work on with some other news organizations. But I think that's more of an issue for publicity than addressing the copyright claims in the lawsuit. So it's like a sign of kind of goodwill marketing and not so much of like going into the street legal terminology, what's wrong here? Right, because fundamentally, as part of any kind of deal like that, they would need to obtain a license if there is in fact some sort of copyright violation that a court would determine is going on here, which of course is yet to be seen. We don't know how courts are going to come out on the copyright infringement question or unfair use. But in the meantime, something like this would come along with the license from those news organizations, and then they could partner and the cost of that license might be low if they could find a really mutually beneficial partnership. OK, that makes sense. Going back to the post number two, training is fair use, but we provide an opt out because it's the right thing to do. Training AI models using publicly available internet materials is fair use as supported by longstanding and widely accepted prepressants. We view the principles as fair to creators necessary for innovators and critical for US competitiveness. The principle that training AI models is permitted as fair use is supported by a wide range of academics, library associations, other regions and countries, including the European Union, Japan, Singapore, and Israel, also have laws that permit training models and copyright content in advance for AI innovation, advancement, and investment. That being said, legal right is less important to us than being good citizens. We have led an AI industry in providing a simple opt out process for publishers to prevent our tools from accessing their sites, which New York Times adopted in August 2023. So I don't mean you and Joe were talking about updating a web crawler to see if they could make a jerk an opt out copyright material. It kind of sounds like they gave New York Times an option later on in August to have some type of functionality. We'll have to hear about point two, what your thoughts are on that. Yeah, absolutely. So this is the part that really gets into the legalies. So they're saying here that training is a fair use. What they mean is that training constitutes a transformative use such that that first factor of the fair use analysis that we talked about last time is going to go in favor of opening eye. That's what they're starting. And to recap for those who didn't see that part, there's four key factors for fair use and the fair use analysis that's a defense to copyright infringement. So even if you infringe a copyright, even if you're engaged in copying or reproduction, you can get out of legal liability for that. If you meet the fair use factors, that's a case by case determination. And some of the key factors include the purpose and character of the use, whether that use is transformative, whether that use is commercial, and also factors like how much is being used and how it affects the market. So if they're trying to develop some system where they're going to be linking to the New York Times articles, only including a small snippet where they're giving an opt out, that's something where they're hoping that's going to support a fair use analysis but fundamentally, they're relying upon an assertion that fair use applies here because the use is transformative. Now, it's interesting that in their blog post, they say that there is longstanding and widely accepted precedent, they don't link to that. So what they're relying on is likely the precedent related to search engine technology, because that's the precedent that's out there right now on this topic of whether something that happens on the internet is going to be a transformative fair use of material that's being used for various search functions. And in those cases, courts have found that that's a transformative fair use, but only for small snippets, only for the purpose of linking to those original sources. And so it's not entirely as clear as this blog post makes it out to be. Now, it's quite possible that courts could rule in their favor on the fair use analysis and say that this is impact to transformative fair use, but they have a lot of things going against them relative to a search engine, like how much of the content is being used. And that's why later on, they start to talk more about how this complete regurgitation is not a common phenomena, because that would really undermine some of their fair use analysis. But we also have to separate out these two processes of training versus outputs. So here, training is fair use. They're talking about training being transformative, being something fundamentally different than the practice of producing news articles for consumption by a consumer. So that's the argument they make. There is no clear precedent on that in the United States right now. And they mentioned that many other countries have past laws that say that that's going to be a fair use in part, because they want to get the business of the new tech companies that are engaged in AI. And they cite to a number of scholars here in their blog post, including several legal scholars that make arguments as to why training of AI should be considered fair use. Some scholars have argued, for example, for a principle of fair learning that any kind of learning by an AI model should be considered fair use. But again, that's scholarship. That's not courts. And we don't know yet what courts are going to determine on this fair use factor. Well said. So they're definitely going into new territory where the law is still catching up, and they're trying to make it look like, no, this has already been decided already without Google's doing things. So this is why we have you on the show. Thank you for catching that. Number three, regurgitation is rare bug that we're working to drive to zero. Our models are designed and trained to learn concepts in order to apply them in new problems. Memorizations are rare failure of the learning process that we're continually making progress on. But it's more common when particular content appears more than once in training day, like if pieces of appear on lots of different public websites. So we have measures in place to limit inadvertent memorization and prevent regurgitation in model outputs. We also expect our users to act responsibly, intentionally manipulating our models to regurgitate is not an appropriate use for technology and is against our terms of use. Just as humans obtain a broad education to learn how to solve new problems, we want our AI models to observe the range of the world's information, including from every language, culture, and industry. Because models learn from the enormous aggregate of human knowledge and anyone sector including news, is a tiny slice to overall training data at any single data source, including New York Times is not significant for the models intended learning. You have the floor. Yeah, so here they're trying to say that it's not our fault if a user does prompt after prompt after prompt and ends up with a regurgitation. They're saying that that's a violation of their terms of use to intentionally regurgitate copyrighted material. This is potentially something that they're trying to say to avoid indirect copyright infringement liability, saying that they don't have control over their users creating regurgitated content and that they are doing everything that they can to eliminate regurgitated content when they find it. This could help in their indirect infringement case. If they can show that they have no control and they're doing everything they can to stop infringement on their platform, this is something that might be useful for that. And so putting that in the terms of use, saying you're not allowed to do that, that could be helpful. But it's going to depend on how everything actually works in practice, how fast they're putting these kind of measures in place, how effective these measures are. Because ultimately it's the responsibility of the platform to go and try to make sure that there's not going to be copyright infringement from using their content and that there's essentially, depending on which method of indirect infringement you're looking at, they're going to want to show, for example, that there is a substantial non-infringing use, that they're not contributing or encouraging their users to engage in copyright infringement and that they're not profiting primarily from copyright infringement and that they don't have control over the copyright infringement. So that's what they're trying to say here. Putting measures in place to prevent regurgitation is critically important to help support their defense on those indirect liability points, especially deduplicating trying to get rid of problems with the data set that are contributing to the higher likelihood of copyright infringement. If there's something in the data set that's making that more likely, they need to get rid of that as soon as possible. Well said, a lot of great points you made. And going back to what they said, memorizations are rare failure of a learning process that we're continually making progress on. So Joe, it has done a lot of deep-dive podcast episodes here. Where we talk about when they're training these models to get to the point where they actually can be able to produce good outputs. There's a point where you want the models to start being able to understand general concepts and not just regurgitate information to you. And so when they start regurgitating, they consider it like overfit. And it's like the last thing they want for these models. They want it to be able to understand concepts and be able to conceptualize. So it was nice to see that they called that out. We also expect our users to act responsibly. I like that. I really do. It'll be interesting though to see, because I don't remember when I go and chat GPT, you've never said anything like, hey, also don't ask specifically for regurgitation to certain articles or something. So it'll be interesting that they make it like, I don't want them to be GDPR obnoxious of like a pop-up. Remember, don't ask for certain news articles. Would it be interesting if they get more in your face that way? Also, if they go into the backend system prompt. So like when we type into something chat GPT, there's also some other pre-prompts of that we don't see that says don't respond with inappropriate material of law. If they sneak in there, don't regurgitate like certain articles from X, Y, and Z. So I thought that was interesting. And then also they said in their training data, including news, is a tiny slice of overall training data. And I go to our last episode where Joe is saying, if you look at all the information they're training on, I would be shocked if at New York Times was more than like, I don't think that quarter or a half percent or something. So. That part is really fascinating as a legal matter because it's unclear if that's actually something that can be considered as part of the copyright fair use analysis. It would be novel for a court to consider that as part of the fair use analysis. Typically, when you're looking at the fair use factor that talks about the amount and substantiality of the use, they're looking at how much of the original content was taken. So if you take a small sliver of the original content like a few sentences at the beginning of a news article, that's typically what you would consider as part of the fair use analysis. Are you doing a few sentences? Or are you taking the entire article? Now, there's no question here that they are taking the entire article. So for that typical consideration of the fair use factor, it wouldn't matter if they're also taking the full article for thousands of other articles from hundreds of other sources. That's not part of the traditional fair use analysis. Now, there's no reason though why courts could not potentially expand their considerations, because ultimately, the fair use defense is something where it's a balancing of many factors and policy considerations. And so we could see courts deciding to look at the fact that this is one small sliver of the training data, but typically, we don't look at how the accused and fringer is using it other than how much of the original is being used. Does that make sense? Oh, it makes perfect sense. And I got to throw you a curve ball real quick. Did you ever work on, because you said you worked in private practice, did you ever work in any M&A by any chance when you did the... I did some M&A work, yeah. So, and I'm not going to quote this properly, because I'm not an M&A lawyer. I'm more of M&A HR guy. You're the one who negotiates all the terms of the deal. I'm the one who comes from the pot of cash and gives it to people and this org stuff. But there's a thing called the Herfindal Hirschman Index. And basically, this is on the Wikipedia. It's a common measure of market concentration is used to determine market competitiveness often pre and post-merger acquisition and M&A transactions. And basically, the feds use it to say like, okay, if Google acquires, or McDonald's acquires breakeeing, what percentage of the hamburger markets are going to get? And if it's too much, then pump the brakes on this. Do you think they're going to try to create a measure eventually some way in the fair use side? Again, I'm a technical debt-perfect easy on me. That says like, okay, well, we look at the percentage of training data here, and it's only the point 0.005. So the case on fair use open eyes making stands. But if it was above a certain threshold, it actually doesn't stand because now you're really just taking corporate information and reaching yourself on. Love to hear what you think. Yeah, so we haven't had any court decisions to my knowledge that have gone to that side of the fair use analysis and expanded that fair use factor of the amount and substantiality of the use to look at what portion of the use affects the business of the accused infringer. Typically, they've just looked at how much is being taken from the owner of that work. Now, there were some opportunities in prior cases for courts to do that, but ultimately those cases settled. So for example, in some of the case law around use of digitization of books, many of those cases, you have the entirety of the book being digitized, but you also have thousands, tens of thousands of other books being digitized as well. And there's this argument that, look, you can't really create a system like this, whether that's an AI or whether that's a digitized library without including many different types of works. So those arguments, they haven't carried the day yet in a previous case, and it would be a novel extension of the fair use analysis for a court to consider that this particular article or that article is only a small sliver of the overall training data. That would be a very novel situation. I could imagine a court potentially considering that, but the more likely place for courts to consider something like that is in the context of damages. To say, for example, there is a copyright infringement, there is no fair use defense, and we are going to award damages, but those damages are going to be very small, because it only contributed this amount to the database or only caused this amount of harm. Now, we do have those statutory damages that can come into play for copyright infringement, which is one of the reasons why all of these plaintiffs against open AI are pursuing copyright infringement instead, because they know that if they were to pursue actual damages, they would run up against that wall that their work only forms a small portion of the training data. So they're relying mostly on these statutory remedies instead of actual damages. And copyright is one of the only ways to do that. I think that's why those plaintiffs are pursuing copyright as the main line of attack here. So good. OK, you've got to, let's, for us, noobs, there are statutory damages that you mentioned, and then there is the other damages, I'm sorry, I apologize. Absolutely. Actual damages. And actual damages, you have to sharpen your pencil right and be able to be like, here's a quantifiable amount. Whereas statutory, you can say, they violate this law 15 trillion times. Is there like a set amount of money that they get for each violation? You can explain that to us real quick. Yeah, so there is some set amounts in the statute that vary from a low amount of $750 to something high, like $150,000. And that'll depend on things like intent, willfulness. And how is the person behaving with regard to the content? Are they really just a counterfeiter or are they a pirate? Are they somebody that's engaging in this conduct willfully? Or is this somebody that's an innocent infringer, somebody that had no idea that the content was even subject to copyright? And I think here we're looking at somewhere in between. And this part, we don't know exactly what the court would find in terms of willfulness here. But I don't think we're looking at innocent infringement here. So we're probably looking at some of the standard statutory damages. And that's going to be based on the number of works infringed. In the original lawsuit, or did New York Times already say, like how many times they think there is a statute violation? And so could some quantify it, but go ahead. So they didn't quantify it in their complaint. What they did say was that they typically licensed articles out for something along the lines of $1,000 per article and that we're looking at many articles, potentially being infringed. And so if you look at statutory damages, let's say if there were 100,000 copyrighted articles that are still that were subject to these kinds of problems, then you could be looking at millions of dollars. of damages based on statutory remedies alone. And then you also have statutory remedies available for violation of the Digital Millennium Copyright Act, which is for removal of the notice, this is by the New York Times, or information about the author. So that's going to be an additional set of statutory remedies typically lower than the ones for copyright infringement, but they're still meaningful. Gotcha. So New York Times is going to try their damnness to say that like it's your fault that Jordan went to our chat GPT and searched for New York Time article. It's not Jordan's ass. It's you'd have to pay up. And they're going to try to get a log of all 150,000 and 100,000 times if someone entered it and see if they could possibly get a thousand dollars for each time that happened. Well, I think it depends on what theory of copyright in liability that they end up succeeding on if any. So if they're able to succeed on the outputs and saying that we're getting regurgitated outputs here, that's a much cleaner case than the one that relies on the training data where you're going to have all these questions around fair use. And so that's why in the blog post, OpenAI is focusing extensively on this question of regurgitation and is it normal for regurgitation to occur? What are the conditions under which it occurs? Part of that is because there's three potential claims of copyright violations here for, I guess, if you include DMCA. But for the copyright infringement claims, you've got direct, vicarious, and contributory liability, vicarious, and contributory are two forms of indirect copyright infringement. That's basically saying that opening eye is responsible for the infringement of the users. And then you've got the direct copyright infringement saying that opening eye itself is engaged in copyright infringement. And now you could say that opening eye itself is potentially engaged in copyright infringement if it's regurgitating copyrighted content because it is publishing or reproducing the content to a third party. And so that could constitute a reproduction under the copyright act. And so if these regurgitations are occurring frequently enough, they could be facing that direct liability. And then you have separate questions around the training. And so I think the strategy is going to, it's going to depend on which one of those theories and whether it's on the training or on the outputs. But if you have a, if you have a bunch of users that are getting regurgitated outputs commonly as a result of certain aspects of the code that make it very likely to get those regurgitations, that makes the claims of copyright infringement either direct or indirect in the outputs much more likely. Well said another curve ball. Do you remember back in the, in the old, I'm an old 38 year old millennial. I'm not going to ask about if you're a millennial or G or what it would Z or whatever you are. But okay, awesome. My people represent, okay. Remember back in our day when you used their thing called Napster. Yeah. You could go out of line and you could, well, you never did it because you were going to law school with me. I'm shady in a meth lab. I would use Napster to download songs legally. When Napster went to quarter, what not, were they trying to, was the music industry trying to get similar case against them saying that like you were 80 embedding Jordan getting copyright material so that you were at fault for this. Yes. But kind of similar lawsuit. Yes, exactly. So they were also trying to bring claims of indirect infringement against at that time Groxter. The main case is against Groxter who came up after Napster went under. And Quartz said, you know, look, we've got, they have 90% of their content is copyright and infringing content. And so this is really problematic. They were aware of what they pushed for it. And so there are rare circumstances where a court will find indirect copyright liability. And those are, those are some of those contexts. If you go to the operating here to peer network in which you're promoting copyright infringement, that's going to be one of them. And but opening where we are saying, look, we're not, we're not Groxter. We're not Napster. People are not coming to us for the purpose of trying to obtain copyrighted content that they can't get on their own. They're coming to us for a lot of different purposes. There is a substantial non-infringing use of our system. Exactly. And, and well said, thank you. And I didn't know this was even possible. You could get a New York Times article on this. I was too busy like being a good Catholic and trying to say, hey, chat GPT, can you get a nice Ian Creed? Now rewrite Jesus as Sam Altman and talk about how he's being crucified by other people in tech. I had no idea if you used it to just copyright New York Times article. That's what the internet archives for. But anyways, thank you, well said, let's go to point four. The New York Times is not telling the full story. Our discussions of New York Times had appeared to be progressing constructively through our last communication in the summer 19th. The negotiations focused on the high value partnership around real-time display and attribution in chat GPT, in which New York Times would gain a new way to connect with their existing and new readers. And our users would gain access to their reporting. We'd explain New York Times that like any single source, their content did meaningful, meaningfully contribute to the training of our existing models and also wouldn't be sufficiently impacting for future training. Their lawsuit in December 27th, which we learned about by reading the New York Times, came to the surprise and disappointed me to a certain end. They had to read New York Times. I'm being so happy. How normal is that? I thought it was like knock-knock. You would be shocked. You would be shocked how normal it is. Really long? Yeah. It happens all the time with these major lawsuits. Yes. So we often would monitor our gosh. My very early use of automation in my legal profession was that one time when I was a first year, I was tasked with monitoring news sites for overnight while we were trying to figure out if someone was going to file a lawsuit or not. And so we were, and so I was supposed to sit there hitting refresh on the New York Times homepage. And I was like, I'm not going to stay up all night hitting refresh on the New York Times homepage, so I set up a Google alert. Look at you there. There you go. 10, 10. You automate, just like a true engineer. You're an engineer mindset. Did you ever watch a substance back in? I didn't look to build for eight hours overnight, but at least you know. Right. You should build for the alert. Yeah. So yes, it's very common. It's very common when you've got really huge lawsuits that might be pending that you won't find out about it. Part of this is because it's very hard to set up automated alerts for a PASER, which is the place where most of these things are getting uploaded after their filed. And sometimes it takes a little bit of time for the court to get everything put up electronically. You can file a paper copy of a complaint and you can also serve it in some way that it's, you know, sitting in some, in the desk of some intake person. And, you know, it doesn't get all the way up to the legal department by that afternoon. Right. So sometimes it sometimes you're going to hear about it first from a news organization. And then you have to go contact the other side's lawyer and say, you know, I heard from the news that you filed something against me. Can you please send it to me? I heard you're talking shit and court that's going on here. I want to be an adult, serve it to me directly. Right. And actually something interesting here is that there's an extension of time that you get to respond to these lawsuits if you do something called a waiver of service. So if you find out from the news that you got sued, you can go reach out. You obviously haven't received service yet a service of process. So you can say, I agree to a waiver of service of process. This requirement that we're supposed to notify people that were filing lawsuits against them. And you're not going to have to go bring somebody to hand me the thing by hand. And in exchange, I'm going to get extra time to answer your complaint. So here, open AI has waived service of process, which means that they're going to get 60 days instead of the usual 21 to respond to the complaint, which means that we're going to see their actual legal response in time at the end of February. And you're going to be back for I don't know if you read the onion, but there's a period of time when Uber, like last decade, was getting sued like every second. And then they did a fake post where they said, now, Uber users can sue inside the app while they're writing for their taxi. That's funny. Okay. So so going back to the floor, the floor was New York Times is not telling us the full story. Also, the Silicon Valley investors club don't forget to like and subscribe and join us on patreon.com forward. So I just think talking to Chris Delaser, lawyer and also legal professor at Cleveland State. Along the way, they had mentioned seeing some regurgitation of their content by repeatedly refusing to share any examples, despite our commitment to investigate and fix any issues. We've demonstrated how seriously we treat this as a priority, such as in July, when we took down chat, you could feature me, you'll have to relearn it could be it could reproduce real-time content in unintended ways. Interestingly, the regurgitation's New York Times induced appear to be from years old articles that have proliferated on multiple third party websites. It seems like they intentionally manipulate prompts, often including lengthy excerpts of the article in order to get our model the regurgitate. Even when using such prompts, our models don't typically behave that way. The New York Times insinuates, which suggests they either instructed the model to regurgitate or cherry pick their examples or many attempts shots fired. So I this will be really fascinating because ultimately the process by which New York Times generated the responses that they included in their complaint will be the subject of discovery. So when you file a lawsuit, you have the right to ask questions of the other side. You can ask written questions called inirrogatories. And one of the first standard written questions that you ask is please describe how you came to this conclusion in this paragraph of your complaint or please produce all of the documents that support the allegation in your complaint or that refer to the allegation in your complaint. And so this is something that's going to come out in very, very early discovery. New York Times has an obligation to preserve the documents that they generate once they're aware of the likelihood of litigation. And so they should have copies of all of the files that they use to produce the content. And if not, I'm sure opening I probably has access to it. And so we'll see if any of the things that opening I is alleging occurred here actually occurred and we'll see that in discovery. Now discovery is something that's going to be private between the parties until it becomes the subject of some sort of pending. Sorry, I'm sorry, I'm sorry to get off. I feel really bad. Can you just explain what discovery means for our folks and then continue what you're saying? Absolutely. Thanks for that. So discovery is a process during the course of a lawsuit where the parties can find out information from each other. And so this could be asking questions. This could be producing documents, requests to produce documents. It could be a request for admission, meaning please admit that you used this process in order to generate this result or other types of admissions that they want to obtain. It could be also depositions. So depositions are where you ask questions to a person live. And this is something that's recorded. And if you say something in a deposition, it has to be true. And if you say something false in a deposition, it could result in what's called impeachment, meaning that you're going to undermine your credibility later on in trial. And you can use some of the deposition testimony as the basis for impeaching or undermining that trial testimony. Ultimately, all of that discovery, that process of gathering documents, information, and questions that's all going to be private between the parties. They're not going to share that publicly in many situations. Now they may do so if there's no confidentiality restrictions imposed on the content, but typically there's some amount of confidentiality produced or there's some amount of confidentiality restrictions on most of those initial document productions. And then you could request to the court to unseal any of those materials or to remove some of the confidentiality on some of those materials. Now the parties will negotiate at the beginning of the proceeding for the scope of that confidentiality. And they may request that some of those documents be deemed not confidential for the purpose of releasing it to the public. Typically you want to have some restrictions in your discovery that the use is going to be limited to use for the lawsuit. And so in those situations, which is a very common place, you're not going to see these kinds of documents getting thrown out to the public immediately. You're going to have to wait for that information to be support or evidence or an attachment to some later motion that's filed publicly with the court. And then the public can get access to it by reviewing those attachments for the motion. So something like a summary judgment motion that could happen in on the time scale of say six months to a year or maybe a year and a half, depending on when discovery closes. So usually summary judgment is something that happens after the close of discovery. That's a motion for a judgment as a matter of law based on the facts that have been disclosed to date. And at those times, that's when you'll typically see release of this information. So if, if in fact, it's true what OpenAI is saying that the New York Times intentionally manipulated the prompts and engaged in prompt engineering to make it more likely for regurgitation to occur and that they cherry picked those to only things where there were duplications in the data set that made regurgitation more likely to occur. Then that's going to come out in discovery and that is going to be something that is going to be used by OpenAI in something like a summary judgment motion. It certainly would be used at trial when this goes to trial because that could be something that sways a jury decision on this matter. I think it's hard to say exactly how that would support or undermine any of the copyright claims because ultimately if there is a regurgitation, it's not entirely, it doesn't really matter for the direct copyright infringement claim how that regurgitation came about. Now for the indirect claims that intent is going to matter and how hard it is to get the result is going to matter. But for direct infringement, was there a reproduction produced by this thing, by this program? That's something where it's not going to matter how that regurgitation came about. Thank you. Well said. A new question. Have you ever been part, is it possible like when discovery is happening, both councils are talking and something gets shared in discovery and it's like, oh, that just made this case is over. There's literally the person saying, we're going to steal this and we're going to screw them over and here's how we're doing it. It's all intentional. Is there a way for both councils to get together and be like, we go to trial, you're cut. Do you want to just settle out right now? Does that ever happen? Yeah, that sometimes happens. Although oftentimes, strategically when you find something like that, it's better to not give away that you found something like that so that you don't tip off the other side. So you have to make really strategic decisions about when to release that kind of information. And I think here, OpenAI is taking more of a public relations approach rather than a legal gotcha approach and trying to say, we want to make sure that the public doesn't view us as somebody that steals from creators and that this rare occurrence. I think that's what they're really going for here because as a legal matter, you could imagine that it would be really useful to save that for a deposition of whoever it was that did these prompts. And go in and say, you know, you have a theme, let's say oftentimes if you're crafting a trial strategy, you're going to have a themes document where you're going to go through and say, okay, what are the legal points that I need to make? What are the elements of those causes of action? For the indirect infringement copyright claims, we want to try to show that this is not common on our platform that we don't profit from or encourage any type of infringement. And so we're going to try to show that any regurgitation that does occur is because of user error and user flouting of our terms of service. And that's going to be their theme. Now, they could come up with that theme and keep it secret. And then when they're going into depositions, they save for some key deposition, let's say the person that engaged in the prompts, this idea that, wow, you really had to engage in quite a lot of prompt engineering to get this out. Why did you choose this article to try? Is it because you knew that this article was reproduced across multiple platforms? And you knew based on your education and artificial intelligence, the duplication of data is more likely to lead to regurgitation. Is that why you picked that article? Right? That's how they would do that in a deposition. And in that scenario, it can be helpful to save that for the deposition and do that gotcha then. So that you get the person on the stand to not have a plan for how to respond to that. Because if their attorneys get wind, that's the way that you want to ask the question. They're going to prep their witness to pivot and not answer that question. Right? You have to sometimes get in there in a way that the other attorney hasn't yet prepped the witness on. That's really, really hard when you're going against these top firms who are going to have a huge map that not only looks at, let's say, the OpenAI theme, but also looks at the New York Times themes. And says, what do we think their themes are? If we were them, what would their themes be? You kind of read team, the legal strategy, right? This is fantastic. Side note. So at one point, Google was just getting sued so many times. We were spending obscenes amounts and discovery and our head of legal was like, all right, so any emails that you have that are older than 18 months, they're not tagged are just good to disappear. And everyone was like, wait, what? I've been working here for a decade and I'm in acquisitions and I need information for context for future deals. And so there used to be the Super Bowl ad where it showed this dad who just had a kid. And so he wanted to do a log of her life. And so she created a Google account for her and every month, like, to yourself, you're so beautiful, you're so great, you're so smart and every year. And it was really cute. And then so after the SDP, STP, SVP, came out with that. Google had their own internal meme generator, which is just what we had a engineering team that would make it image generators. You could just clown on all the executives and we would do it all the time. It was great. It was a great part of our culture. It was a way to like say unspoken truths like because if you get dogged on a lot a lot of the executives would be like yeah there's probably something wrong with this project we got up next. And so sub would the Super Bowl ad versus like deer Sophie and they put deer Sophie. I'm currently in Google right now so probably be deleted. But dad wants to know I love you. Oh. So I'll get it. I don't so Austin points on discovery and how this is all going. Yeah. The reason why that happens by the way is that you have to keep the types of documents that you have to keep are anything that is potentially relevant to a litigation that you are in or believe is likely to occur. And then you also have to keep documents that are regularly kept in the ordinary course of business. And so changing how you keep files in the ordinary course of business helps to prevent situations where in the far future you know you have 10 years of emails to go back to that are still kept in the ordinary course of business. Now I don't know if I would have advised a client to do that or if I were in the legal group I don't know if I would have advised that because I think it's kind of a big stretch to say well you're changing policy because there's lots of lawsuits and so we don't anticipate a particular litigation but we're going to do this because there might be something. I just started. I mean technically maybe it's true but companies do all sorts of crazy things to try to avoid any kinds of downfalls from litigation. But I've definitely seen situation where a 10-year-old email just is used to drown somebody. I mean it's fun as a lawyer frankly. Right. I remember there are emails from Tate. But I walk through it going I'm pretty sure he said this. Exactly. And what's hilarious is like there's an old saying it's a little common value that like you basically your product reflects your org structure and what your org really cares about. So at Google there is some Gmail features like remember when Gmail like seven or eight years ago started to be able to respond like three words or from with like responses to your email like that sounds great or whatnot. And you're probably like this is great. So hopefully this will continue to the point where it's going to respond to paragraph and then do more things for me but it didn't because of legal is like a word about but what did happen is legal came out with product is hey with a great feature this is called confidentiality feature where you send the email and it like goes away or destroys itself like after a while or something don't you all want that small businesses that were like no one wanted that. Just you lawyers you wanted. Right. So so anyways we love Google legal they're great. So let's go to the next segment of section four. Despite their claims this misuse is not typical or allowed user activity and is not a substitute for New York times regardless we are continually making our systems more resistant to adversarial tax to regurgitate training data and have already made such progress in our recent models. We regard the New York Times lawsuit to be without merit still we are hopeful for constructive partnership New York Times and respects long history which includes reporting the first working neural network over 60 years ago and championing first amendment freedoms. We look forward to continue collaboration with news organization helping elevate their ability to produce quality journalism by realizing the transform potential AI. Now that you may you made that really great point of like their legal strategy where they could have not even mentioned anything or regutation or anything but this is it's like we're going to kind of beat you but the same time we're focusing more on like hey Kumbaya we believe in the rights of people having their their information and we're not we're not the anti-Christ when other people to work with us. So it seems like really interesting take and I feel very sad for opening eyes head of legal counsel because he was like oh Christmas week vacation opens up a New York Times he's like oh god would you probably expect it here she probably expected it no too right I mean I mean a lot of people a lot of a lot of lawyers do it intentionally judges will not like it if you file things intentionally to disrupt somebody's holidays but it happens but that's why we have such a long period of time in part to respond to complaints you don't have to respond the day of Christmas unless it's a temporary restraining order or something like that one reason that I don't envy judges is needing to respond to Christmas day temporary restraining orders or something like that. I did draft I think I mentioned last time I had to draft on a Christmas day which was not fun. But open open your presence and everything now I have to go back and draft a restraining order on Santa. Wow but I will say the tone here of the blog post suggests that open AI wants to continue negotiations with New York Times and other news organizations it sounds like they're saying open AI is saying that they felt a little bamboozled by receiving the lawsuit during what they thought were ongoing negotiations and I wonder how much of that truly reflects the scope of the negotiations if open AI was in fact aware that the negotiations had broken down you know in the New York Times complaint they suggest that the negotiations had broken down or reached an impasse and oftentimes you will tell the other side hey I think these negotiations have reached an impasse so I'm going to go ahead and file the lawsuit the downside with doing that is that then the other side could try to preempt you and file a lawsuit in a jurisdiction that's better for them so you can file something called a declaratory judgment action as soon as you have reason to believe that the other side is pursuing a case against you so if somebody else says negotiations broke down we're done we're filing a lawsuit if your lawyers can write something faster you can file something that afternoon in California instead if you feel like the California case law is better for you than the New York case law and so I think that might have been what New York Times was worried about if they had signaled to open AI that the negotiations were over and they wanted to file a lawsuit they were probably afraid that opening AI was going to preempt them okay that again your teacher you law things about law you truly are a professor this is fantastic thank you very much don't forget to like and subscribe um you could so you okay I'm opening AI here New York Times and you're like I'm gonna sue Jordan whatever and then I get wind oh she's probably gonna sue me I can then go to the court of California and to say she's probably gonna sue me about these things let's talk about it here like how yeah so there's something called the Declaratory Judgment Act and it allows people to it's designed with a reasonable purpose which is we want to prevent situations where someone is bullying somebody with threats about about the legal system and we don't want to allow a bully to say you need to pay up or we're gonna file a lawsuit against you um and that person have no recourse to kind of end that sort of threat you want the person who's being threatened to be able to say well I'm gonna just ask the court to conclude that you don't have a case and so that's why we have the Declaratory Judgment Act and it allows these kind of Declaratory Judgment Actions meaning we're gonna file and say there is in fact no copyright claim here but um sometimes it can be useful to convey to another side that you think that you're at an impasse and you want to file a case because that could mean that maybe they are more willing to bend in negotiations when you say look I think we've reached the end of where we can negotiate but sometimes sometimes it's a bullying tactic and you want to be able to file a lawsuit against them when they're doing that it's it's a really hard decision to make but the court system allows either side to file if they're in a situation where somebody else has threatened to sue them. Gotcha well thank you I did not did not know about that um I think Joe's probably gonna sue me so I'm gonna file a lawsuit in California right now. Um I wonder though how I wonder and we'll find out perhaps in discovery um what happened during the breakdown of these negotiations now typically um information about negotiations is protected from discovery um and protected against being used in a lawsuit in many situations um it may come up in the context of royalty discussions um but uh that's more applicable in a patent case and in a copyright case where you've got these statutory damages so I I think here um I I don't know and I don't know if we'll find out how genuine it was that um New York Times sort of cut off the negotiations and filed the lawsuit because they thought there was nothing left or did they cut off negotiations and filed a lawsuit because they were worried what might happen and they didn't want to tip off open AI enough that opening I would file a lawsuit. Opening I sounds like they were confused and like they thought negotiations were going on um but we don't know. Yeah I know that's I'm glad you're giving us legal perspective because I think uh me and Joe's default would be like oh okay this is great they now have a new story to push forward in the news with the Elias S. Seberg and Sam Altman drama that we got in November it's kind of over I mean eventually maybe Eliya might leave but that story's done so let's get a new story going let's go they'll our current lawsuit against the Eval AI company but you make a lot of great points of they had good reasons maybe go out there first and get the lawsuit in there in the right court they want to have. We don't know. Yeah we don't know um so we're gonna go to our um our patreon supporter question so if you're watching right now go to patreon.com for a slice of stick and if you're in the enthusiast here or Bbq Club you can ask our guest questions and so one of our enthusiasts um named Sim Sim thanks for asking it he asked the question he said Krista what were your favorite legalese that was used in the response and second do you think that open AI's assertion that New York Times is not telling a full story indicates a bigger strategic play what scenarios would that strategic lawyers be looking at now and three how do you think this might influence others thinking of bringing a case against open AI slash Microsoft Sim thanks for the question. Yeah thanks for that so I'll take it kind of in reverse order the last question was how is this going to affect others potentially bringing a lawsuit well we have a number of lawsuits that have been filed against open AI already um all bringing similar types of claims asserting that training data is infringement and trying to make out some case for uh output being infringing because that's a much easier case to bring if they can show that that infringing output so here when they're making these statements in section four of this blog post by open AI that regurgitation is not common that it requires prompt engineering and manipulation and violation of their terms of use to obtain they're trying to say to other people hey this is not copyright infringement this is users violating our terms of use this is not our fault therefore we're not liable for indirect copyright infringement now they still could be facing those direct copyright infringement claims if there are in fact close enough reproduction that are being generated by their system but they're trying to avoid that and say that that is not a common occurrence and we'll have to wait and see also what courts say with regards to who is responsible for the outputs that are being generated is that in fact a direct infringement by open AI or is that a direct infringement by the user um and then if it's a direct infringement by the user then the cause of action against open AI would be for indirect infringement so what does this mean for other lawsuits well probably there if anybody else has concerns with what open AI is doing they're probably going to copy the format of the New York Times lawsuit and try to see what happens in that lawsuit and they might try to wait a little bit to file because they might want to wait and see what happens in this lawsuit and then you would ask a few other questions um things like what kind of legalese is present in the response well um they don't use a lot of legalese here i think this blog post is mostly a public relations response that's designed to convey a message hey open AI is a good guy New York Times is the bad guy they're the ones that are manipulating the data uh in order to try to bring a flimsy lawsuit that's what open AI is trying to convey here so i don't really see a lot of legalese i think they're trying to make this accessible uh when we get the final response in late February i imagine that that is going to be focused on legal responses and saying that there is a fair use defense that this is transformative fair use that there is no in fact um direct infringement occurring here and that they haven't met the standards for indirect infringement under some of the previous case law like the ones uh regarding beta max or things like that and then um let's see was there another question in there uh let me see real quick i think you covered it what were your favorite legalese use talked about that do you think that open AI assertion but New York Times not telling a full story indicates a bigger strategic play strategic play you entered that previously and you answered yeah you answered all three so it's fantastic um any other concluding thoughts before you run because it is seven o'clock your site and we really appreciate your time here so thank you no this is great um i really appreciate you having me on i think my concluding thought would be we don't know what's going to happen until a court decides these issues we could have more and more lawsuits we'll have more back and forth between the parties we'll have discovery taking place we'll have a lot of press releases taking place and many of those are going to be from a place of legal strategy but also from a place of managing public opinion around what's happening in the lawsuits but none of this is going to matter from a legal perspective until we actually get a decision from some court whether it's in this lawsuit or perhaps more likely in one of the other lawsuits against opening eye that were filed earlier um we're gonna have to wait and see do courts consider training to be fair use do courts consider outputs to be a direct infringement by the company that made the program that produced those outputs those are all questions that we can't know the answer to and that there's no precedent that really helps completely inform us of the answer so i think all of it before then is pontificating sure right christis right and um but you know what you're going to get an answer here in February when christina comes back to get first of all look at the rebuttal statement the rebuttal statements from opening eye and then when we get back get a judgment and legal proceedings christina christina will be here but more importantly christina we need people to go to christina laser.com at chrsta laser lsr.com i believe your hubby is actually working on improving the site so they bring out this is so no no no that's not you you're impeccable to him he needs a hurry you're the best because you allowed us to have her on here thank you and then also christis create releasing a research paper um christ a 30 seconds at high level overview of the research papers we can talk about. So i'm working on research that looks at the educational backgrounds of u.s federal judges and is looking at whether we need more judges with stem educations in the united states and that research should be out in February. That was better than 306 those 15 um so if you all enjoy this i'm going to link you to another video where we talked to christia last week we're going to deeper dive about the lawsuit um don't forget to like and subscribe support us on patreon.com forge slash sick and you all have a great day thank you

